{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "short _dist_ll_lines_deepa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqTvTCrjv7Fl",
        "outputId": "7f11460a-e23e-48e8-c353-dcbbc75a2105"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze1P0lmAwEH0"
      },
      "source": [
        "import pandas as pd\r\n",
        "import math\r\n",
        "import random\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhuIgIyTzw7O"
      },
      "source": [
        "X1=[]\r\n",
        "Y1=[]\r\n",
        "M1=[]\r\n",
        "X2=[]\r\n",
        "Y2=[]\r\n",
        "M2=[] \r\n",
        "for i in range(0,100):\r\n",
        "    X1.append(round(random.uniform(1,9),2))\r\n",
        "    Y1.append(round(random.uniform(1,9),2))\r\n",
        "    M1.append(round(random.uniform(1,9),2))\r\n",
        "    X2.append(round(random.uniform(1,9),2))\r\n",
        "    Y2.append(round(random.uniform(1,9),2))\r\n",
        "    M2.append(round(random.uniform(1,9),2))\r\n",
        "    \r\n",
        "\r\n",
        "Distance=[]\r\n",
        "for i in range (0,100):\r\n",
        "    d1=((X1[i])+(Y1[i])+(M1[i]))/math.sqrt((abs(X1[i])**2)+(abs(Y1[i])**2))\r\n",
        "    d2=((X2[i])+(Y2[i])+(M2[i]))/math.sqrt((abs(X2[i])**2)+(abs(Y2[i])**2))\r\n",
        "    Distance.append(round(abs((d1)-(d2)),2))\r\n",
        "\r\n",
        "Data = pd.DataFrame()\r\n",
        "Data['X1'] = X1\r\n",
        "Data['Y1'] = Y1\r\n",
        "Data['M1'] = M1\r\n",
        "Data['X2'] = X2\r\n",
        "Data['Y2'] = Y2\r\n",
        "Data['M2'] = M2\r\n",
        "Data['Distance']= Distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeF4s80k0Dia"
      },
      "source": [
        "Data.to_csv('Shortest_dist.csv',index=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "j_Tr1B4z1b8F",
        "outputId": "519529cd-92a7-45e0-bb42-ae464d8444be"
      },
      "source": [
        "import pandas as pd\r\n",
        "df=pd.read_csv(\"Shortest_dist.csv\")\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>Y1</th>\n",
              "      <th>M1</th>\n",
              "      <th>X2</th>\n",
              "      <th>Y2</th>\n",
              "      <th>M2</th>\n",
              "      <th>Distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.34</td>\n",
              "      <td>2.28</td>\n",
              "      <td>3.01</td>\n",
              "      <td>2.61</td>\n",
              "      <td>4.12</td>\n",
              "      <td>4.32</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.40</td>\n",
              "      <td>7.24</td>\n",
              "      <td>6.04</td>\n",
              "      <td>8.42</td>\n",
              "      <td>3.20</td>\n",
              "      <td>2.61</td>\n",
              "      <td>0.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.61</td>\n",
              "      <td>4.23</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1.13</td>\n",
              "      <td>1.02</td>\n",
              "      <td>7.58</td>\n",
              "      <td>4.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.24</td>\n",
              "      <td>3.45</td>\n",
              "      <td>8.44</td>\n",
              "      <td>4.63</td>\n",
              "      <td>7.80</td>\n",
              "      <td>5.77</td>\n",
              "      <td>1.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.46</td>\n",
              "      <td>6.76</td>\n",
              "      <td>3.70</td>\n",
              "      <td>3.55</td>\n",
              "      <td>3.67</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>6.68</td>\n",
              "      <td>3.53</td>\n",
              "      <td>5.22</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.69</td>\n",
              "      <td>2.15</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1.59</td>\n",
              "      <td>4.12</td>\n",
              "      <td>1.94</td>\n",
              "      <td>1.65</td>\n",
              "      <td>4.26</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>8.01</td>\n",
              "      <td>6.06</td>\n",
              "      <td>8.26</td>\n",
              "      <td>6.49</td>\n",
              "      <td>1.99</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>4.20</td>\n",
              "      <td>1.72</td>\n",
              "      <td>8.90</td>\n",
              "      <td>4.49</td>\n",
              "      <td>7.39</td>\n",
              "      <td>5.61</td>\n",
              "      <td>1.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>7.86</td>\n",
              "      <td>1.77</td>\n",
              "      <td>7.85</td>\n",
              "      <td>3.70</td>\n",
              "      <td>7.45</td>\n",
              "      <td>4.86</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      X1    Y1    M1    X2    Y2    M2  Distance\n",
              "0   3.34  2.28  3.01  2.61  4.12  4.32      0.13\n",
              "1   3.40  7.24  6.04  8.42  3.20  2.61      0.51\n",
              "2   7.61  4.23  1.75  1.13  1.02  7.58      4.83\n",
              "3   1.24  3.45  8.44  4.63  7.80  5.77      1.58\n",
              "4   8.46  6.76  3.70  3.55  3.67  1.30      0.08\n",
              "..   ...   ...   ...   ...   ...   ...       ...\n",
              "95  6.68  3.53  5.22  6.59  4.69  2.15      0.38\n",
              "96  1.59  4.12  1.94  1.65  4.26  1.25      0.16\n",
              "97  8.01  6.06  8.26  6.49  1.99  1.88      0.70\n",
              "98  4.20  1.72  8.90  4.49  7.39  5.61      1.24\n",
              "99  7.86  1.77  7.85  3.70  7.45  4.86      0.24\n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WdxdZVe1irb"
      },
      "source": [
        "X = df[['X1','Y1','M1','X2','Y2','M2']]\r\n",
        "y = df['Distance']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkf1A_Fs1zYX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kifxxpIH2GMz"
      },
      "source": [
        "from keras.models  import Sequential\r\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\r\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG8_2HiP2YQ9"
      },
      "source": [
        "ANN_MODEL = Sequential([\r\n",
        "    Dense(6, input_shape=(6,), activation=\"relu\"),\r\n",
        "    Dense(1,activation='linear')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cprUMHwV2cfw",
        "outputId": "d22a4159-0600-44f9-a741-d91f7c1d82f2"
      },
      "source": [
        "ANN_MODEL.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 49\n",
            "Trainable params: 49\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4kqp5lU2hKr",
        "outputId": "a70ed58c-9fdd-4dfb-9194-40508b9733ec"
      },
      "source": [
        "ANN_MODEL.compile(loss='mean_squared_error', optimizer='adam')\r\n",
        "model_1 = ANN_MODEL.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=80)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.4583 - val_loss: 1.0329\n",
            "Epoch 2/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4040 - val_loss: 1.0243\n",
            "Epoch 3/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3546 - val_loss: 1.0196\n",
            "Epoch 4/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.4121 - val_loss: 1.0130\n",
            "Epoch 5/80\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4000 - val_loss: 1.0099\n",
            "Epoch 6/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3925 - val_loss: 1.0040\n",
            "Epoch 7/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3218 - val_loss: 0.9969\n",
            "Epoch 8/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3950 - val_loss: 0.9879\n",
            "Epoch 9/80\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.3684 - val_loss: 0.9803\n",
            "Epoch 10/80\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3248 - val_loss: 0.9800\n",
            "Epoch 11/80\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3092 - val_loss: 0.9828\n",
            "Epoch 12/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2737 - val_loss: 0.9818\n",
            "Epoch 13/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3491 - val_loss: 0.9815\n",
            "Epoch 14/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3312 - val_loss: 0.9835\n",
            "Epoch 15/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3163 - val_loss: 0.9861\n",
            "Epoch 16/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.3122 - val_loss: 0.9877\n",
            "Epoch 17/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3282 - val_loss: 0.9858\n",
            "Epoch 18/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.3359 - val_loss: 0.9821\n",
            "Epoch 19/80\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.2977 - val_loss: 0.9779\n",
            "Epoch 20/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2441 - val_loss: 0.9760\n",
            "Epoch 21/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2958 - val_loss: 0.9748\n",
            "Epoch 22/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2988 - val_loss: 0.9769\n",
            "Epoch 23/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2766 - val_loss: 0.9771\n",
            "Epoch 24/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2858 - val_loss: 0.9761\n",
            "Epoch 25/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.2799 - val_loss: 0.9737\n",
            "Epoch 26/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.2845 - val_loss: 0.9750\n",
            "Epoch 27/80\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.2534 - val_loss: 0.9723\n",
            "Epoch 28/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2890 - val_loss: 0.9740\n",
            "Epoch 29/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.2709 - val_loss: 0.9779\n",
            "Epoch 30/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2207 - val_loss: 0.9807\n",
            "Epoch 31/80\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.2900 - val_loss: 0.9823\n",
            "Epoch 32/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2786 - val_loss: 0.9841\n",
            "Epoch 33/80\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2695 - val_loss: 0.9858\n",
            "Epoch 34/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2249 - val_loss: 0.9876\n",
            "Epoch 35/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2332 - val_loss: 0.9886\n",
            "Epoch 36/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2287 - val_loss: 0.9898\n",
            "Epoch 37/80\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2571 - val_loss: 0.9928\n",
            "Epoch 38/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2161 - val_loss: 0.9925\n",
            "Epoch 39/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2340 - val_loss: 0.9931\n",
            "Epoch 40/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2302 - val_loss: 0.9965\n",
            "Epoch 41/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2445 - val_loss: 0.9981\n",
            "Epoch 42/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2410 - val_loss: 0.9955\n",
            "Epoch 43/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2259 - val_loss: 0.9960\n",
            "Epoch 44/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2677 - val_loss: 0.9986\n",
            "Epoch 45/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2236 - val_loss: 1.0018\n",
            "Epoch 46/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2216 - val_loss: 1.0069\n",
            "Epoch 47/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2171 - val_loss: 1.0142\n",
            "Epoch 48/80\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2022 - val_loss: 1.0183\n",
            "Epoch 49/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2657 - val_loss: 1.0217\n",
            "Epoch 50/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2490 - val_loss: 1.0195\n",
            "Epoch 51/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1743 - val_loss: 1.0175\n",
            "Epoch 52/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1950 - val_loss: 1.0170\n",
            "Epoch 53/80\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2348 - val_loss: 1.0195\n",
            "Epoch 54/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1762 - val_loss: 1.0200\n",
            "Epoch 55/80\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2293 - val_loss: 1.0246\n",
            "Epoch 56/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2011 - val_loss: 1.0280\n",
            "Epoch 57/80\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.2312 - val_loss: 1.0313\n",
            "Epoch 58/80\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.2213 - val_loss: 1.0352\n",
            "Epoch 59/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1883 - val_loss: 1.0372\n",
            "Epoch 60/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1988 - val_loss: 1.0408\n",
            "Epoch 61/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1699 - val_loss: 1.0462\n",
            "Epoch 62/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2411 - val_loss: 1.0526\n",
            "Epoch 63/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1809 - val_loss: 1.0587\n",
            "Epoch 64/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1928 - val_loss: 1.0650\n",
            "Epoch 65/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1767 - val_loss: 1.0687\n",
            "Epoch 66/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2174 - val_loss: 1.0692\n",
            "Epoch 67/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2026 - val_loss: 1.0701\n",
            "Epoch 68/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1843 - val_loss: 1.0686\n",
            "Epoch 69/80\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1643 - val_loss: 1.0678\n",
            "Epoch 70/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.2071 - val_loss: 1.0694\n",
            "Epoch 71/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2044 - val_loss: 1.0736\n",
            "Epoch 72/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1733 - val_loss: 1.0798\n",
            "Epoch 73/80\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1618 - val_loss: 1.0862\n",
            "Epoch 74/80\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.1624 - val_loss: 1.0937\n",
            "Epoch 75/80\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.1481 - val_loss: 1.1002\n",
            "Epoch 76/80\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2152 - val_loss: 1.1041\n",
            "Epoch 77/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.2095 - val_loss: 1.1080\n",
            "Epoch 78/80\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1701 - val_loss: 1.1106\n",
            "Epoch 79/80\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1877 - val_loss: 1.1095\n",
            "Epoch 80/80\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1971 - val_loss: 1.1066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrm7dYHX3LEw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}